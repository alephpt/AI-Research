{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO48Z39cW79jKzsCuTr4cd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alephpt/AI_Projects/blob/main/GPT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kwjBAG2zQ3-5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as fn\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # Number of Sequences to Process in Parallel\n",
        "block_size = 32 # Max Content Length for Predictions\n",
        "max_iterations = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iterations = 200 # Number of iterations before saving state\n",
        "n_embed = 64 # Maps the input sequence into high-dimensional space\n",
        "n_head = 4 # Attention head for multi-head attention layers\n",
        "n_layers = 4\n",
        "dropout = 0.0"
      ],
      "metadata": {
        "id": "QwE7Io8fS-e-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "bible_url = 'https://www.o-bible.com/download/kjv.txt'\n",
        "bible = requests.get(bible_url)\n",
        "bible_text = bible.text.split(\"\\n\")\n",
        "bible_text.remove(bible_text[0])"
      ],
      "metadata": {
        "id": "cNYvFvEvWQjO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bible_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dghIlZ7iVoL",
        "outputId": "330da34a-213d-4140-fd47-8433d44481d1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ge1:1 In the beginning God created the heaven and the earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(bible.text)))\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocab Size:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Q4MPZ6iqfF",
        "outputId": "4f4e5078-19fa-466b-cb39-0f989cff9abb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size: 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch: i for i, ch in enumerate(vocab)}\n",
        "itos = { i: ch for i, ch in enumerate(vocab)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: \"\".join([itos[i] for i in l])\n",
        "\n",
        "nums = encode(\"Today is the day.\")\n",
        "words = decode(nums)\n",
        "\n",
        "print(\"nums\", nums)\n",
        "print(\"words\", words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU1VGta-mTL0",
        "outputId": "fca0c5bb-35b0-45cc-95ff-0f77c076f21d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nums [41, 61, 50, 47, 71, 1, 55, 65, 1, 66, 54, 51, 1, 50, 47, 71, 8]\n",
            "words Today is the day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(bible.text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "id": "uZGhGt1cpw4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9 * len(data)) # train on the first 90%\n",
        "training_data = data[:n]\n",
        "validation_data = data[n:]\n",
        "block_size = 8\n",
        "training_data[:block_size + 1]\n",
        "x = training_data[:block_size]\n",
        "y = training_data[1:block_size + 1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "id": "UmlC4J0NqOWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "  data = training_data if split == \"train\" else validation_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "  y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "Hqv1tKTxqgdO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)"
      ],
      "metadata": {
        "id": "4clRbxrTsZ0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t + 1]\n",
        "    target = yb[b, t]\n",
        "    print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "id": "e_s-uB1hsz10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "\n",
        "  for split in ['train', 'eval']:\n",
        "    losses = torch.zeros(eval_iterations)\n",
        "    for k in range(eval_iterations):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "mDWDYISdtLWC"
      },
      "execution_count": 80,
      "outputs": []
    }
  ]
}